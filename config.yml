topicsFilePath: data/topics/topics-task2.xml
qrelsRelevanceFilePath: data/qrels/touche-task2-2022-relevance.qrels
qrelsQualityFilePath: data/qrels/touche-task2-2022-quality.qrels
qrelsStanceFilePath: data/qrels/touche-task2-2022-stance.qrels
runsDirectoryPath: data/runs/
corpusFilePath: data/corpus/touche-task2-passages-version-002.jsonl
cacheDirectoryPath: data/cache/

runs:
#- stanceTagger: original
#- stanceTagger: ground-truth
#- stanceTagger: bigscience/T0
#- stanceTagger: bigscience/T0pp
#- stanceTagger: bigscience/T0_3B
#- stanceTagger: facebook/bart-large-mnli
#- stanceTagger: google/flan-t5-base
#- stanceTagger: text-davinci-003
#  stanceTaggerThreshold: 0.00
#  stanceTaggerCutoff: 20
#  stanceReranker: stance-first # FIRST, SECOND, or NEUTRAL
#  stanceReranker: subjective-stance-first # FIRST or SECOND
#  stanceReranker: original
#  stanceRerankerCutoff: 20
#  fairnessReranker: original
#  fairnessReranker: alternating-stance
#  fairnessReranker: inverse-stance-gain
#  fairnessReranker: boost-minority-stance
#  fairnessRerankerCutoff: 20

#- stanceTagger: original
#  stanceReranker: original
#  fairnessReranker: original
#- stanceTagger: ground-truth
#  stanceReranker: original
#  fairnessReranker: original
#- stanceTagger: text-davinci-003
#  stanceTaggerCutoff: 5
#  stanceReranker: original
#  fairnessReranker: original
#- stanceTagger: google/flan-t5-base
#  stanceTaggerThreshold: 0.4
#  stanceTaggerCutoff: 20
#  stanceReranker: original
#  fairnessReranker: original
#- stanceTagger: facebook/bart-large-mnli
#  stanceTaggerThreshold: 0.25
#  stanceTaggerCutoff: 20

- stanceTagger: ground-truth
  stanceReranker: original
  fairnessReranker: original
- stanceTagger: ground-truth
  stanceReranker: stance-first
  fairnessReranker: original
- stanceTagger: ground-truth
  stanceReranker: original
  fairnessReranker: alternating-stance
- stanceTagger: ground-truth
  stanceReranker: stance-first
  fairnessReranker: alternating-stance

stanceTaggerZeroShotThreshold: 0.25

#maxTeams: 3
#maxRunsPerTeam: 2

measuresRelevance:
- nDCG@5
measuresQuality:
- nDCG@5
measuresStance:
- F1@20
- F1All
- JudgedAll
#- PropFirst@20
#- PropSecond@20
#- PropNeutral@20
#- PropNo@20
#- Confidence
#- rND(group_col='stance_label',tie_breaking='group-ascending')@5
#- rKL(group_col='stance_label',tie_breaking='group-ascending')@5
#- rRD(group_col='stance_label',tie_breaking='group-ascending')@5
- rND(group_col='stance_label',tie_breaking='group-ascending',groups='FIRST,SECOND,NEUTRAL')@5
- rKL(group_col='stance_label',tie_breaking='group-ascending',groups='FIRST,SECOND,NEUTRAL')@5
- rRD(group_col='stance_label',tie_breaking='group-ascending',groups='FIRST,SECOND,NEUTRAL')@5
#measuresDiversity:
#- alpha_nDCG@5
#measuresPerQuery: true

significanceLevel: 0.05

metricsOutputFilePath: data/metrics.csv
#metricsOutputFilePath: data/metrics.xlsx

# Remove documents without judgments before evaluation.
#filterByQrels: true

# Attempt to work offline.
# Won't work unless PyTerrier and NLTK dependencies have previously been downloaded.
#offline: true

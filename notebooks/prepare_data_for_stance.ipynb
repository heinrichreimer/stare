{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def mask_text(object1, object2, text):\n",
    "    l = re.findall(r\"[\\w']+|[.,!?;:]\", text)\n",
    "    object1 = object1.capitalize()\n",
    "    object2 = object2.capitalize()\n",
    "    if object1 in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object1]\n",
    "        for i in indices:\n",
    "            l[i] = 'FIRST_ENTITY'\n",
    "    if object1+'s' in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object1+'s']\n",
    "        for i in indices:\n",
    "            l[i] = 'FIRST_ENTITY'\n",
    "    if object1.lower() in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object1.lower()]\n",
    "        for i in indices:\n",
    "            l[i] = 'FIRST_ENTITY'\n",
    "    if object1.lower()+'s' in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object1.lower()+'s']\n",
    "        for i in indices:\n",
    "            l[i] = 'FIRST_ENTITY'\n",
    "    if object2 in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object2]\n",
    "        for i in indices:\n",
    "            l[i] = 'SECOND_ENTITY'\n",
    "    if object2+'s' in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object2+'s']\n",
    "        for i in indices:\n",
    "            l[i] = 'SECOND_ENTITY'\n",
    "    if object2.lower() in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object2.lower()]\n",
    "        for i in indices:\n",
    "            l[i] = 'SECOND_ENTITY'\n",
    "    if object2.lower()+'s' in l:\n",
    "        indices = [i for i, x in enumerate(l) if x == object2.lower()+'s']\n",
    "        for i in indices:\n",
    "            l[i] = 'SECOND_ENTITY'\n",
    "    out_text = \" \".join(l)\n",
    "    return re.sub(r' (?=\\W)', '', out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic</th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>narrative</th>\n",
       "      <th>object_first</th>\n",
       "      <th>object_second</th>\n",
       "      <th>stance_label</th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "      <th>name</th>\n",
       "      <th>stance_value</th>\n",
       "      <th>text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24500</td>\n",
       "      <td>100</td>\n",
       "      <td>Should I learn Python or R for data analysis?</td>\n",
       "      <td>Wondering whether you should use Python or R f...</td>\n",
       "      <td>Relevant documents should compare two programm...</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>clueweb12-1509wb-05-28610___12</td>\n",
       "      <td>92.317061</td>\n",
       "      <td>levirank_psuedo_relevance_feedback+voting</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>R is a free, open source statistics package wr...</td>\n",
       "      <td>0</td>\n",
       "      <td>SECOND_ENTITY is a free, open source statistic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Topic                                          query  \\\n",
       "0       24500    100  Should I learn Python or R for data analysis?   \n",
       "\n",
       "                                         description  \\\n",
       "0  Wondering whether you should use Python or R f...   \n",
       "\n",
       "                                           narrative object_first  \\\n",
       "0  Relevant documents should compare two programm...       Python   \n",
       "\n",
       "  object_second  stance_label                              ID      score  \\\n",
       "0             R             3  clueweb12-1509wb-05-28610___12  92.317061   \n",
       "\n",
       "                                        name  stance_value  \\\n",
       "0  levirank_psuedo_relevance_feedback+voting          -1.0   \n",
       "\n",
       "                                                text  rank  \\\n",
       "0  R is a free, open source statistics package wr...     0   \n",
       "\n",
       "                                         text_masked  \n",
       "0  SECOND_ENTITY is a free, open source statistic...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_RUNS =\"../data/tmp/\"\n",
    "\n",
    "run_df = pd.read_csv(os.path.join(PATH_RUNS, \"sample-run.csv\"))\n",
    "run_df['text_masked'] = run_df.apply(lambda x: mask_text(x['object_first'], x['object_second'], x['text']), axis=1)\n",
    "replace_values = {'FIRST' : 2, 'SECOND' : 3, 'NO' : 0, 'NEUTRAL' : 1}                                                                                          \n",
    "run_df = run_df.replace({\"stance_label\": replace_values}).rename({\"qid\": \"Topic\", \"docno\": \"ID\"}, axis=1)\n",
    "run_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                        touche-task2-2022-relevance.qrels\n",
      "touche-task2-2022-quality.qrels  touche-task2-2022-stance.qrels\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/qrels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic</th>\n",
       "      <th>query</th>\n",
       "      <th>description</th>\n",
       "      <th>narrative</th>\n",
       "      <th>object_first</th>\n",
       "      <th>object_second</th>\n",
       "      <th>stance_label</th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "      <th>name</th>\n",
       "      <th>stance_value</th>\n",
       "      <th>text</th>\n",
       "      <th>rank</th>\n",
       "      <th>text_masked</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24500</td>\n",
       "      <td>100</td>\n",
       "      <td>Should I learn Python or R for data analysis?</td>\n",
       "      <td>Wondering whether you should use Python or R f...</td>\n",
       "      <td>Relevant documents should compare two programm...</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>clueweb12-1509wb-05-28610___12</td>\n",
       "      <td>92.317061</td>\n",
       "      <td>levirank_psuedo_relevance_feedback+voting</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>R is a free, open source statistics package wr...</td>\n",
       "      <td>0</td>\n",
       "      <td>SECOND_ENTITY is a free, open source statistic...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Topic                                          query  \\\n",
       "0       24500    100  Should I learn Python or R for data analysis?   \n",
       "\n",
       "                                         description  \\\n",
       "0  Wondering whether you should use Python or R f...   \n",
       "\n",
       "                                           narrative object_first  \\\n",
       "0  Relevant documents should compare two programm...       Python   \n",
       "\n",
       "  object_second  stance_label                              ID      score  \\\n",
       "0             R             3  clueweb12-1509wb-05-28610___12  92.317061   \n",
       "\n",
       "                                        name  stance_value  \\\n",
       "0  levirank_psuedo_relevance_feedback+voting          -1.0   \n",
       "\n",
       "                                                text  rank  \\\n",
       "0  R is a free, open source statistics package wr...     0   \n",
       "\n",
       "                                         text_masked  Score  \n",
       "0  SECOND_ENTITY is a free, open source statistic...    1.0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "DIMENSION = \"stance\"\n",
    "\n",
    "#RESULT_PATH = \"../../touche22-data/results/task\"+str(TASK)+\"/\"\n",
    "QREL_PATH = \"../data/qrels/touche-task2-2022-stance.qrels\"\n",
    "#RUN_PATH = \"../../touche22-data/runs/task\"+str(TASK)+\"/*/output/*\"\n",
    "\n",
    "qrels = (\n",
    "    pd.read_csv(QREL_PATH, header=None, sep=\" \")\n",
    "    .rename({0: \"Topic\", 1: \"Q0\", 2: \"ID\", 3: \"Score\"}, axis=1)\n",
    "    .drop(\"Q0\", axis=1)\n",
    ")\n",
    "\n",
    "df_with_qrels = (\n",
    "    run_df\n",
    "    .merge(\n",
    "        qrels,\n",
    "        on = [\"Topic\", \"ID\"],\n",
    "        how = \"left\"\n",
    "    )\n",
    ")\n",
    "df_with_qrels = df_with_qrels.replace({\"Score\": replace_values}).dropna(subset=['Score'])\n",
    "df_with_qrels.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "def transform_train(df):\n",
    "    df[\"text_a\"] = ['FIRST_ENTITY is good'] * len(df)\n",
    "    # df[\"text_a\"] = df[\"cleaned_question\"] # to take the whole question before the [SEP] token\n",
    "    df[\"text_b\"] = df[\"text_masked\"] # the part after the [SEP] token\n",
    "    df[\"labels\"] = df[\"stance_label\"]\n",
    "    return df\n",
    "\n",
    "#PATH_MODEL = \"/mnt/ceph/storage/data-in-progress/data-research/arguana/fair-ranking/checkpoints/checkpoints-roberta-o1-good-masked\"\n",
    "PATH_MODEL = \"/mnt/ceph/storage/data-in-progress/data-research/arguana/fair-ranking/checkpoints/checkpoints-roberta-o1-good-masked/checkpoints\"\n",
    "\n",
    "model = ClassificationModel(\"roberta\", PATH_MODEL, num_labels=4, use_cuda=False, cuda_device=0)\n",
    "pred_df = transform_train(df_with_qrels)\n",
    "_, raw_outputs, _ = model.eval_model(pred_df)\n",
    "pred_probs = softmax(raw_outputs, axis=1)\n",
    "pred_preds = np.argmax(raw_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 793, 2: 803, 0: 35, 1: 131})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df_with_qrels.stance_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.31      0.06        35\n",
      "           1       0.11      0.85      0.20       131\n",
      "           2       0.59      0.18      0.27       803\n",
      "           3       0.48      0.11      0.18       793\n",
      "\n",
      "    accuracy                           0.20      1762\n",
      "   macro avg       0.30      0.36      0.18      1762\n",
      "weighted avg       0.49      0.20      0.22      1762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = df_with_qrels.stance_label.tolist(), y_pred = pred_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1763330638967639"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true = df_with_qrels.stance_label.tolist(), y_pred = pred_preds, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
